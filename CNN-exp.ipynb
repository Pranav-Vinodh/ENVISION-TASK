{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mplt\n",
    "import keras \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.iloc[:,1:]\n",
    "y = train_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test =  train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values.reshape(-1,28,28,1)\n",
    "x_test = x_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.1, # Randomly zoom image \n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32,activation='relu',strides=1,padding = 'same', kernel_size=(4,4),data_format='channels_last',input_shape =(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32,activation='relu',strides=1,padding='same',kernel_size=(4,4),data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=2,pool_size=(3,3),padding='valid'))\n",
    "model.add(Dropout(0.25))          \n",
    "\n",
    "model.add(Conv2D(filters = 64,activation = 'relu',strides=1,padding='same',kernel_size=(4,4),data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64,activation = 'relu',strides=1,padding='same',kernel_size=(4,4),data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=2,pool_size=(3,3),padding='valid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1181/1181 [==============================] - 42s 34ms/step - loss: 0.3355 - accuracy: 0.9034 - val_loss: 0.0905 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1181/1181 [==============================] - 40s 34ms/step - loss: 0.1262 - accuracy: 0.9631 - val_loss: 0.0846 - val_accuracy: 0.9757 - lr: 9.0000e-04\n",
      "Epoch 3/40\n",
      "1181/1181 [==============================] - 42s 35ms/step - loss: 0.1004 - accuracy: 0.9707 - val_loss: 0.0362 - val_accuracy: 0.9888 - lr: 8.1000e-04\n",
      "Epoch 4/40\n",
      "1181/1181 [==============================] - 42s 36ms/step - loss: 0.0842 - accuracy: 0.9762 - val_loss: 0.0536 - val_accuracy: 0.9864 - lr: 7.2900e-04\n",
      "Epoch 5/40\n",
      "1181/1181 [==============================] - 43s 37ms/step - loss: 0.0737 - accuracy: 0.9779 - val_loss: 0.0321 - val_accuracy: 0.9890 - lr: 6.5610e-04\n",
      "Epoch 6/40\n",
      "1181/1181 [==============================] - 43s 36ms/step - loss: 0.0596 - accuracy: 0.9828 - val_loss: 0.0446 - val_accuracy: 0.9869 - lr: 5.9049e-04\n",
      "Epoch 7/40\n",
      "1181/1181 [==============================] - 44s 38ms/step - loss: 0.0560 - accuracy: 0.9838 - val_loss: 0.0404 - val_accuracy: 0.9862 - lr: 5.3144e-04\n",
      "Epoch 8/40\n",
      "1181/1181 [==============================] - 44s 37ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.0252 - val_accuracy: 0.9926 - lr: 4.7830e-04\n",
      "Epoch 9/40\n",
      "1181/1181 [==============================] - 43s 37ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 0.0303 - val_accuracy: 0.9921 - lr: 4.3047e-04\n",
      "Epoch 10/40\n",
      " 465/1181 [==========>...................] - ETA: 24s - loss: 0.0424 - accuracy: 0.9874"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 40\n",
    "history = model.fit(datagen.flow(x_train,y_train,batch_size=batch_size),epochs=epochs,\n",
    "validation_data=(x_test,y_test),verbose=1,steps_per_epoch=x_train.shape[0]//batch_size,callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
